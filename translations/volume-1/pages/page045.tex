\thispagestyle{fancy}
\fancyhead[LO]{1. Counting and Numbers.   2. Addition}

\vspace{0.5cm}

latter case obtained number that it is the sum of the two numbers obtained in the former case, and these two numbers are called the \textit{summands} of the sum. The transition from two numbers to a single one just described is called \textit{addition}. Counting and adding thus differ only in that counting deals with a single group, while adding deals with two groups of units. To indicate that from two numbers \textit{a} and \textit{b} a third number \textit{s} has emerged through addition, one places the symbol $+$ (plus) between the two summands. From the definitions of being greater and of addition follows: A sum is greater than one of its summands, namely by the other summand. When \textit{a} $>$ \textit{b}, then \textit{a} can be the sum of two summands, one of which is \textit{b}.

From the concept of counting follows that there can always be only one number which is the sum of any two numbers, and conversely that there can also be only one number which, when combined with a given number through addition, leads to a \textit{greater} given number as sum.

Since the result of counting is independent of the order in which one counts, it must be:

\begin{center}
$a + b = b + a$
\end{center}

One calls the law expressed herein the \textit{commutation law}\textsuperscript{11)} of addition. Despite \hfill this \hfill law, \hfill one \hfill can \hfill conceptually \hfill distinguish \hfill the \hfill two

\vfill
\leftline{\rule{2in}{0.4pt}}
\vspace{0.2cm}
{
\footnotesize
11) If + is the symbol for a very generally conceived connection of two quantities, then for this connection the \textit{commutative} law applies when \textit{a} + \textit{b} = \textit{b} + \textit{a}, the \textit{associative} law applies when (\textit{a} + \textit{b}) + \textit{c} = \textit{a} + (\textit{b} + \textit{c}). Furthermore, if × is the symbol for a second generally conceived connection, then the \textit{distributive} law applies to both when (\textit{a} + \textit{b}) × \textit{c} = (\textit{a} × \textit{c}) + (\textit{b} × \textit{c}), or when (\textit{a} × \textit{b}) + \textit{c} = (\textit{a} + \textit{c}) × (\textit{b} + \textit{c}). The distinction of these three basic laws and their names are first found in Germany in \textit{H. Hankel} (Theory of Complex Number Systems, Leipzig 1867), in England already since about 1840, and (according to Hankel) the terms commutative and distributive were first used by \textit{Servois} (Gergonne's Ann., Vol. V, 1814, p. 93), associative probably first by \textit{Hamilton}. These three basic laws also play a fundamental role in more general relationships than arithmetic operations, such as in formal mathematics, logic calculus and conceptual notation. (Cf. here Vol. VI.) In logic calculus, \textit{a} + \textit{b} means everything that is either \textit{a} or \textit{b}, \textit{a}·\textit{b} everything that is both \textit{a} and \textit{b}. For each of these operations, the commutative and associative laws apply. Additionally, the distributive law applies in both forms, as (\textit{a} + \textit{b}) · \textit{c} = (\textit{a} · \textit{c}) + (\textit{b} · \textit{c}) and furthermore (\textit{a} · \textit{b}) + \textit{c} = (\textit{a} + \textit{c}) · (\textit{b} + \textit{c}). \textit{E. Schröder} drew attention to this in his work "Operation Circle of Logic Calculus" (Leipzig 1877).

}
